{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee59ab1-d09b-4ad9-b813-56605be6c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Ans.Web Scraping is a technique used to extract data from websites. It involves fetching web pages, parsing the HTML or other markup language used to\n",
    "    structure the page, and then extracting the desired information for further use. Web scraping is used for various purposes, and it's a valuable \n",
    "    tool for gathering data from the internet. \n",
    "    \n",
    "    Three areas where Web Scraping is used to get data :\n",
    "    E-commerce Price Monitoring\n",
    "    Real Estate Listings\n",
    "    News and Content Aggregation\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476845c5-7dea-490c-a345-a1ff3c225293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "Ans.\n",
    "   1.Manual Copy-Pasting: You manually select and copy data from a webpage, then paste it into a file or application.\n",
    "\n",
    "   2.HTTP Libraries (Requests): You use a program to request a webpage's content, and then the program helps you extract the information you need \n",
    "    from that content.\n",
    "\n",
    "   3.Headless Browsers: It's like having a robot browse the web for you. This robot can click buttons and interact with web pages to get the data you \n",
    "    want.\n",
    "\n",
    "   4.APIs: Some websites have a special door (API) that allows you to ask for specific data in an organized way. It's like ordering from a menu \n",
    "    instead of searching for food in a big kitchen.\n",
    "\n",
    "   5.Scraping Frameworks: You use a specialized tool that helps you build and organize web scrapers efficiently.\n",
    "    \n",
    "   6.Web Scraping Tools and Software: These are user-friendly programs that let you scrape data without writing code. It's like using a wizard to \n",
    "    perform web scraping.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46f4db-0f03-47c7-b711-f32e487731fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Ans.Beautiful Soup is a Python library used for web scraping purposes. It is specifically designed for parsing and navigating HTML or XML documents, \n",
    "    making it easier to extract and manipulate data from web pages. Beautiful Soup is commonly used in web scraping because of its simplicity and \n",
    "    flexibility.\n",
    "    \n",
    "    Here's why it's used:\n",
    "    1.HTML Parsing\n",
    "    2.Simplifies HTML Parsing\n",
    "    3.Data Extraction\n",
    "    4.Error Handling\n",
    "    5.Open Source and Well-Documented\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d01e7-b658-4525-9bcb-feeaf7589b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "Ans.Flask is a lightweight and flexible Python web framework that is often used in web scraping projects for several reasons:\n",
    "    \n",
    "  1.Web Application Development: While web scraping primarily involves extracting data from websites, there are often requirements to build web \n",
    "    applications around the scraped data. Flask allows you to quickly develop web applications to display and interact with the scraped data. \n",
    "    For example, you can create a web interface to search and visualize the scraped information.\n",
    "    \n",
    "  2.API Creation: Flask makes it easy to create APIs (Application Programming Interfaces) that can serve the scraped data to other applications or \n",
    "    services. This is valuable if you want to provide programmatic access to the data you've collected.\n",
    "    \n",
    "  3.Routing and URL Handling: Flask provides a simple and intuitive way to define routes and handle URL routing. This is helpful for setting up \n",
    "    endpoints to trigger specific scraping tasks or to display different views of the data.\n",
    "    \n",
    "  4.Integration with Databases: In many web scraping projects, you may want to store the scraped data in a database for further analysis or reporting.\n",
    "    Flask can be easily integrated with various database systems, allowing you to save and retrieve data efficiently.\n",
    "    \n",
    "  5.Customization: Flask gives you a high degree of control over the structure and behavior of your web scraping application. You can tailor it to \n",
    "    your specific project requirements.\n",
    "    \n",
    "  6.Lightweight and Minimalistic: Flask is known for its simplicity and minimalism, making it a great choice for small to medium-sized web scraping \n",
    "  projects where you don't need the complexity of larger web frameworks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b07725-2920-4552-9479-677553e090a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "Ans.Mainly two sericves are used in this project :\n",
    "   1.Elastic Beanstalk\n",
    "   2.Code Pipeline\n",
    "   \n",
    "   AWS Elastic Beanstalk is a Platform as a Service (PaaS) offering from Amazon Web Services (AWS) that simplifies the deployment, scaling, and \n",
    "   management of web applications and services. It abstracts the underlying infrastructure, allowing developers to focus on writing code and \n",
    "   deploying applications without worrying about the operational complexities of managing servers and networking.\n",
    "   \n",
    "   AWS CodePipeline is a managed continuous integration and continuous delivery (CI/CD) service provided by Amazon Web Services (AWS). It automates\n",
    "   and orchestrates the steps involved in building, testing, and deploying software applications and infrastructure changes. CodePipeline enables teams \n",
    "   to create efficient and reliable software delivery pipelines, streamlining the development process and ensuring the consistent and automated release\n",
    "   of software updates.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
